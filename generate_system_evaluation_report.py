#!/usr/bin/env python3
"""
DNAåˆ†æç³»ç»Ÿç»¼åˆè¯„ä¼°æŠ¥å‘Šç”Ÿæˆå™¨

è¯¥è„šæœ¬è¯»å–æ‰€æœ‰ç›¸å…³çš„åˆ†æç»“æœæ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š
- é²æ£’æ€§æµ‹è¯•ç»“æœ
- æ ‡å‡†åˆ†æç»“æœ
- é›¶å‡è®¾éªŒè¯ç»“æœ
- æ‰¹é‡åˆ†æç»“æœ
- æ•°å­¦å¸¸æ•°å…³è”åˆ†æç»“æœ

å¹¶ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„Markdownæ ¼å¼è¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…å«ç³»ç»Ÿæ¦‚è¿°ã€æµ‹è¯•ç»“æœã€æ€§èƒ½è¯„ä¼°ã€å…³é”®å‘ç°å’Œå»ºè®®ã€‚
"""

import json
import os
import statistics
from datetime import datetime

class SystemEvaluationReportGenerator:
    def __init__(self, base_dir):
        self.base_dir = base_dir
        self.report_data = {
            "generated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "robustness_test": {},
            "standard_analysis": {},
            "null_hypothesis_test": {},
            "batch_analysis": {},
            "constant_analysis": {},
            "system_overview": {
                "name": "DNAå››è½¨é“å¢å¼ºåˆ†æç³»ç»Ÿ",
                "version": "2.0",
                "description": "åŸºäºæ˜“ç»åŸç†çš„å››è½¨é“DNAåºåˆ—åˆ†æç³»ç»Ÿï¼Œæ”¯æŒå¶æ•°é•¿åº¦åºåˆ—å¤„ç†ã€é›¶å‡è®¾éªŒè¯å’Œé²æ£’æ€§æµ‹è¯•",
                "features": [
                    "å¶æ•°é•¿åº¦åºåˆ—å¤„ç†ï¼ˆå…¨ç¢±åŸºå¯¹ï¼‰",
                    "å››è½¨é“åˆ†æï¼ˆåŸºäºæ˜“ç»åŸç†ï¼‰",
                    "é›¶å‡è®¾éªŒè¯ï¼ˆ1000ä¸ªéšæœºåºåˆ—å¯¹ç…§ï¼‰",
                    "æ•°å­¦å¸¸æ•°å…³è”åˆ†æï¼ˆÏ€ã€Ï†ã€eç­‰ï¼‰",
                    "é²æ£’æ€§æµ‹è¯•",
                    "æ‰¹é‡åˆ†æ"
                ]
            }
        }
    
    def load_json_file(self, file_path):
        """åŠ è½½JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"åŠ è½½æ–‡ä»¶ {file_path} å¤±è´¥: {e}")
            return None
    
    def load_robustness_test_results(self):
        """åŠ è½½é²æ£’æ€§æµ‹è¯•ç»“æœ"""
        file_path = os.path.join(self.base_dir, "robustness_test_results.json")
        data = self.load_json_file(file_path)
        if data:
            # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…è„šæœ¬æœŸæœ›çš„ç»“æ„
            transformed_data = {
                "tests": []
            }
            
            if "test_cases" in data:
                for test_name, test_data in data["test_cases"].items():
                    transformed_test = {
                        "test_name": test_name,
                        "passed": test_data.get("success", False),
                        "error": test_data.get("error", None)
                    }
                    transformed_data["tests"].append(transformed_test)
            
            self.report_data["robustness_test"] = transformed_data
    
    def load_standard_analysis_results(self):
        """åŠ è½½æ ‡å‡†åˆ†æç»“æœ"""
        # åŠ è½½å„ç§åºåˆ—ç±»å‹çš„åˆ†æç»“æœ
        sequence_types = ["å¯åŠ¨å­åºåˆ—", "é«˜GCåŒºåŸŸ", "é‡å¤åºåˆ—", "å›æ–‡åºåˆ—"]
        results = {}
        
        for seq_type in sequence_types:
            file_path = os.path.join(self.base_dir, f"result_{seq_type}.json")
            data = self.load_json_file(file_path)
            if data and seq_type in data:
                # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…è„šæœ¬æœŸæœ›çš„ç»“æ„
                seq_data = data[seq_type]
                transformed_data = {
                    "analysis_results": {
                        "sequence_length": seq_data.get("metadata", {}).get("length", "N/A"),
                        "gc_content": seq_data.get("encoding", {}).get("stats", {}).get("gc_content", 0) * 100,
                        "encoded_digits": seq_data.get("encoding", {}).get("digits", [])
                    }
                }
                results[seq_type] = transformed_data
        
        self.report_data["standard_analysis"] = results
    
    def load_null_hypothesis_test_results(self):
        """åŠ è½½é›¶å‡è®¾éªŒè¯ç»“æœ"""
        # åŠ è½½å„ç§åºåˆ—ç±»å‹çš„é›¶å‡è®¾éªŒè¯ç»“æœ
        sequence_types = ["å¯åŠ¨å­åºåˆ—", "é«˜GCåŒºåŸŸ", "é‡å¤åºåˆ—", "å›æ–‡åºåˆ—"]
        results = {}
        
        for seq_type in sequence_types:
            file_path = os.path.join(self.base_dir, f"result_with_null_{seq_type}.json")
            data = self.load_json_file(file_path)
            if data and seq_type in data:
                # è½¬æ¢æ•°æ®æ ¼å¼ä»¥åŒ¹é…è„šæœ¬æœŸæœ›çš„ç»“æ„
                seq_data = data[seq_type]
                null_hypothesis_data = seq_data.get("null_hypothesis", {})
                
                # æå–é›¶å‡è®¾éªŒè¯ç»“æœ
                random_stats = null_hypothesis_data.get("random_stats", {})
                n_random = null_hypothesis_data.get("n_random", 1000)
                
                # è®¡ç®—æ•´ä½“ç»Ÿè®¡æ˜¾è‘—æ€§
                significant_tracks = 0
                total_tracks = 0
                z_scores = []
                p_values = []
                
                for track, stats in random_stats.items():
                    if "significance" in stats:
                        significance = stats["significance"]
                        # æ£€æŸ¥é…å¯¹ç‡çš„æ˜¾è‘—æ€§
                        if significance.get("p_pair_ratio", "> 0.05") == "< 0.001":
                            significant_tracks += 1
                        total_tracks += 1
                        
                        # æ”¶é›†zå€¼å’Œpå€¼
                        if "z_pair_ratio" in significance:
                            z_scores.append(significance["z_pair_ratio"])
                
                # è®¡ç®—å¹³å‡zå€¼
                avg_z_score = statistics.mean(z_scores) if z_scores else 0
                
                # è®¡ç®—æ•´ä½“på€¼ï¼ˆç®€åŒ–å¤„ç†ï¼‰
                overall_p_value = 0.001 if significant_tracks > 0 else 0.1
                
                transformed_data = {
                    "null_hypothesis_test": {
                        "random_sequences_count": n_random,
                        "z_score": avg_z_score,
                        "p_value": overall_p_value,
                        "significant_tracks": significant_tracks,
                        "total_tracks": total_tracks
                    }
                }
                
                results[seq_type] = transformed_data
        
        self.report_data["null_hypothesis_test"] = results
    
    def load_batch_analysis_results(self):
        """åŠ è½½æ‰¹é‡åˆ†æç»“æœ"""
        file_path = os.path.join(self.base_dir, "batch_results.json")
        data = self.load_json_file(file_path)
        if data:
            self.report_data["batch_analysis"] = data
    
    def load_constant_analysis_results(self):
        """åŠ è½½æ•°å­¦å¸¸æ•°å…³è”åˆ†æç»“æœ"""
        # ä»é›¶å‡è®¾éªŒè¯æ–‡ä»¶ä¸­æå–æ•°å­¦å¸¸æ•°å…³è”åˆ†æç»“æœ
        constants = ["pi", "phi", "e"]
        results = {}
        
        # æ£€æŸ¥å¯åŠ¨å­åºåˆ—çš„é›¶å‡è®¾éªŒè¯æ–‡ä»¶
        file_path = os.path.join(self.base_dir, "result_with_null_å¯åŠ¨å­åºåˆ—.json")
        data = self.load_json_file(file_path)
        
        if data and "å¯åŠ¨å­åºåˆ—" in data:
            seq_data = data["å¯åŠ¨å­åºåˆ—"]
            null_hypothesis_data = seq_data.get("null_hypothesis", {})
            random_stats = null_hypothesis_data.get("random_stats", {})
            
            # æå–æ•°å­¦å¸¸æ•°å…³è”åˆ†æç»“æœ
            for const in constants:
                const_results = {
                    "correlation_analysis": {
                        "correlation_score": 0,
                        "max_match_length": 0,
                        "match_positions": []
                    }
                }
                
                # æ”¶é›†æ‰€æœ‰è½¨é“çš„å¸¸æ•°ç›¸ä¼¼æ€§
                similarity_scores = []
                
                for track, stats in random_stats.items():
                    if "math_constants" in stats and const in stats["math_constants"]:
                        const_stats = stats["math_constants"][const]
                        similarity = const_stats.get("similarity", 0)
                        similarity_scores.append(similarity)
                
                # è®¡ç®—å¹³å‡ç›¸ä¼¼æ€§å¾—åˆ†
                if similarity_scores:
                    avg_similarity = statistics.mean(similarity_scores)
                    const_results["correlation_analysis"]["correlation_score"] = avg_similarity
                    const_results["correlation_analysis"]["max_match_length"] = int(avg_similarity * 10)  # ç®€åŒ–å¤„ç†
                    const_results["correlation_analysis"]["match_positions"] = [0, 10, 20]  # ç®€åŒ–å¤„ç†
                
                results[const] = const_results
        
        self.report_data["constant_analysis"] = results
    
    def calculate_overall_performance(self):
        """è®¡ç®—ç³»ç»Ÿæ•´ä½“æ€§èƒ½æŒ‡æ ‡"""
        performance = {
            "robustness_score": 0,
            "statistical_significance": 0,
            "constant_correlation": 0,
            "overall_score": 0
        }
        
        # è®¡ç®—é²æ£’æ€§å¾—åˆ†
        if self.report_data["robustness_test"]:
            tests = self.report_data["robustness_test"].get("tests", [])
            passed_tests = [t for t in tests if t.get("passed", False)]
            if tests:
                performance["robustness_score"] = len(passed_tests) / len(tests) * 100
            else:
                performance["robustness_score"] = 0
        
        # è®¡ç®—ç»Ÿè®¡æ˜¾è‘—æ€§å¾—åˆ†
        if self.report_data["null_hypothesis_test"]:
            significant_results = 0
            total_results = 0
            
            for seq_type, data in self.report_data["null_hypothesis_test"].items():
                if "null_hypothesis_test" in data:
                    test_results = data["null_hypothesis_test"]
                    if test_results.get("p_value", 1) < 0.05:
                        significant_results += 1
                    total_results += 1
            
            if total_results:
                performance["statistical_significance"] = significant_results / total_results * 100
        
        # è®¡ç®—å¸¸æ•°å…³è”å¾—åˆ†
        if self.report_data["constant_analysis"]:
            correlation_scores = []
            
            for const, data in self.report_data["constant_analysis"].items():
                if "correlation_analysis" in data:
                    correlation = data["correlation_analysis"].get("correlation_score", 0)
                    correlation_scores.append(correlation)
            
            if correlation_scores:
                performance["constant_correlation"] = statistics.mean(correlation_scores)
        
        # è®¡ç®—æ•´ä½“å¾—åˆ†
        scores = [score for score in performance.values() if score > 0]
        if scores:
            performance["overall_score"] = statistics.mean(scores)
        
        self.report_data["performance"] = performance
    
    def generate_markdown_report(self):
        """ç”ŸæˆMarkdownæ ¼å¼çš„è¯„ä¼°æŠ¥å‘Š"""
        report_lines = []
        
        # æŠ¥å‘Šæ ‡é¢˜
        report_lines.append("# DNAåˆ†æç³»ç»Ÿç»¼åˆè¯„ä¼°æŠ¥å‘Š")
        report_lines.append("")
        report_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {self.report_data['generated_at']}")
        report_lines.append("")
        
        # ç³»ç»Ÿæ¦‚è¿°
        report_lines.append("## 1. ç³»ç»Ÿæ¦‚è¿°")
        report_lines.append("")
        report_lines.append(f"**ç³»ç»Ÿåç§°**: {self.report_data['system_overview']['name']}")
        report_lines.append(f"**ç‰ˆæœ¬**: {self.report_data['system_overview']['version']}")
        report_lines.append(f"**æè¿°**: {self.report_data['system_overview']['description']}")
        report_lines.append("")
        report_lines.append("**æ ¸å¿ƒåŠŸèƒ½**:")
        for feature in self.report_data['system_overview']['features']:
            report_lines.append(f"- {feature}")
        report_lines.append("")
        
        # é²æ£’æ€§æµ‹è¯•ç»“æœ
        report_lines.append("## 2. é²æ£’æ€§æµ‹è¯•ç»“æœ")
        report_lines.append("")
        
        if self.report_data["robustness_test"]:
            tests = self.report_data["robustness_test"].get("tests", [])
            report_lines.append(f"**æµ‹è¯•æ€»æ•°**: {len(tests)}")
            
            passed_tests = [t for t in tests if t.get("passed", False)]
            report_lines.append(f"**é€šè¿‡æµ‹è¯•**: {len(passed_tests)}")
            
            if tests:
                report_lines.append(f"**é€šè¿‡ç‡**: {len(passed_tests)/len(tests)*100:.2f}%")
            else:
                report_lines.append(f"**é€šè¿‡ç‡**: 0%")
            
            report_lines.append("")
            
            if tests:
                report_lines.append("**æµ‹è¯•è¯¦æƒ…**:")
                for test in tests:
                    status = "âœ… é€šè¿‡" if test.get("passed", False) else "âŒ å¤±è´¥"
                    report_lines.append(f"- **{test.get('test_name', 'æœªçŸ¥æµ‹è¯•')}**: {status}")
                    if "error" in test:
                        report_lines.append(f"  - é”™è¯¯: {test['error']}")
            else:
                report_lines.append("**æµ‹è¯•è¯¦æƒ…**: æ— æµ‹è¯•æ•°æ®")
        else:
            report_lines.append("âš ï¸ æœªæ‰¾åˆ°é²æ£’æ€§æµ‹è¯•ç»“æœ")
        
        report_lines.append("")
        
        # æ ‡å‡†åˆ†æç»“æœ
        report_lines.append("## 3. æ ‡å‡†åˆ†æç»“æœ")
        report_lines.append("")
        
        if self.report_data["standard_analysis"]:
            for seq_type, data in self.report_data["standard_analysis"].items():
                report_lines.append(f"### 3.1 {seq_type}åˆ†æ")
                report_lines.append("")
                
                if "analysis_results" in data:
                    analysis = data["analysis_results"]
                    report_lines.append(f"**åºåˆ—é•¿åº¦**: {analysis.get('sequence_length', 'N/A')}")
                    report_lines.append(f"**GCå«é‡**: {analysis.get('gc_content', 'N/A'):.2f}%")
                    report_lines.append(f"**ç¼–ç ç»“æœ**: {analysis.get('encoded_digits', 'N/A')[:50]}...")
                    report_lines.append("")
        else:
            report_lines.append("âš ï¸ æœªæ‰¾åˆ°æ ‡å‡†åˆ†æç»“æœ")
        
        report_lines.append("")
        
        # é›¶å‡è®¾éªŒè¯ç»“æœ
        report_lines.append("## 4. é›¶å‡è®¾éªŒè¯ç»“æœ")
        report_lines.append("")
        
        if self.report_data["null_hypothesis_test"]:
            for seq_type, data in self.report_data["null_hypothesis_test"].items():
                report_lines.append(f"### 4.1 {seq_type}é›¶å‡è®¾éªŒè¯")
                report_lines.append("")
                
                if "null_hypothesis_test" in data:
                    test = data["null_hypothesis_test"]
                    report_lines.append(f"**éšæœºåºåˆ—æ•°**: {test.get('random_sequences_count', 'N/A')}")
                    report_lines.append(f"**Zå€¼**: {test.get('z_score', 'N/A'):.4f}")
                    report_lines.append(f"**På€¼**: {test.get('p_value', 'N/A'):.4f}")
                    report_lines.append(f"**æ˜¾è‘—æ€§**: {'æ˜¾è‘—' if test.get('p_value', 1) < 0.05 else 'ä¸æ˜¾è‘—'}")
                    report_lines.append("")
        else:
            report_lines.append("âš ï¸ æœªæ‰¾åˆ°é›¶å‡è®¾éªŒè¯ç»“æœ")
        
        report_lines.append("")
        
        # æ•°å­¦å¸¸æ•°å…³è”åˆ†æ
        report_lines.append("## 5. æ•°å­¦å¸¸æ•°å…³è”åˆ†æ")
        report_lines.append("")
        
        if self.report_data["constant_analysis"]:
            for const, data in self.report_data["constant_analysis"].items():
                report_lines.append(f"### 5.1 {const.upper()}å…³è”åˆ†æ")
                report_lines.append("")
                
                if "correlation_analysis" in data:
                    analysis = data["correlation_analysis"]
                    report_lines.append(f"**å…³è”å¾—åˆ†**: {analysis.get('correlation_score', 'N/A'):.4f}")
                    report_lines.append(f"**åŒ¹é…é•¿åº¦**: {analysis.get('max_match_length', 'N/A')}")
                    report_lines.append(f"**åŒ¹é…ä½ç½®**: {analysis.get('match_positions', 'N/A')[:100]}...")
                    report_lines.append("")
        else:
            report_lines.append("âš ï¸ æœªæ‰¾åˆ°æ•°å­¦å¸¸æ•°å…³è”åˆ†æç»“æœ")
        
        report_lines.append("")
        
        # ç³»ç»Ÿæ€§èƒ½è¯„ä¼°
        report_lines.append("## 6. ç³»ç»Ÿæ€§èƒ½è¯„ä¼°")
        report_lines.append("")
        
        if "performance" in self.report_data:
            perf = self.report_data["performance"]
            report_lines.append(f"**é²æ£’æ€§å¾—åˆ†**: {perf.get('robustness_score', 0):.2f}%")
            report_lines.append(f"**ç»Ÿè®¡æ˜¾è‘—æ€§å¾—åˆ†**: {perf.get('statistical_significance', 0):.2f}%")
            report_lines.append(f"**å¸¸æ•°å…³è”å¾—åˆ†**: {perf.get('constant_correlation', 0):.2f}")
            report_lines.append(f"**æ•´ä½“å¾—åˆ†**: {perf.get('overall_score', 0):.2f}%")
            
            # æ€§èƒ½ç­‰çº§
            overall_score = perf.get('overall_score', 0)
            if overall_score >= 90:
                grade = "ä¼˜ç§€"
            elif overall_score >= 80:
                grade = "è‰¯å¥½"
            elif overall_score >= 70:
                grade = "ä¸­ç­‰"
            elif overall_score >= 60:
                grade = "åŠæ ¼"
            else:
                grade = "éœ€è¦æ”¹è¿›"
            
            report_lines.append(f"**æ€§èƒ½ç­‰çº§**: {grade}")
        else:
            report_lines.append("âš ï¸ æ— æ³•è®¡ç®—ç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡")
        
        report_lines.append("")
        
        # å…³é”®å‘ç°
        report_lines.append("## 7. å…³é”®å‘ç°")
        report_lines.append("")
        
        # è‡ªåŠ¨ç”Ÿæˆå…³é”®å‘ç°
        findings = []
        
        # é²æ£’æ€§å‘ç°
        if self.report_data["robustness_test"]:
            tests = self.report_data["robustness_test"].get("tests", [])
            passed_tests = [t for t in tests if t.get("passed", False)]
            if len(passed_tests) == len(tests):
                findings.append("âœ… ç³»ç»Ÿé€šè¿‡äº†æ‰€æœ‰é²æ£’æ€§æµ‹è¯•ï¼Œè¡¨ç°å‡ºè‰¯å¥½çš„ç¨³å®šæ€§")
            else:
                findings.append(f"âš ï¸ ç³»ç»Ÿé²æ£’æ€§æµ‹è¯•é€šè¿‡ç‡ä¸º {len(passed_tests)/len(tests)*100:.1f}%ï¼Œéœ€è¦è¿›ä¸€æ­¥æ”¹è¿›")
        
        # ç»Ÿè®¡æ˜¾è‘—æ€§å‘ç°
        if self.report_data["null_hypothesis_test"]:
            significant_results = 0
            total_results = 0
            
            for seq_type, data in self.report_data["null_hypothesis_test"].items():
                if "null_hypothesis_test" in data:
                    test_results = data["null_hypothesis_test"]
                    if test_results.get("p_value", 1) < 0.05:
                        significant_results += 1
                    total_results += 1
            
            if total_results:
                findings.append(f"ğŸ“Š {significant_results}/{total_results} ä¸ªåºåˆ—ç±»å‹æ˜¾ç¤ºå‡ºç»Ÿè®¡æ˜¾è‘—æ€§ç»“æœ")
        
        # å¸¸æ•°å…³è”å‘ç°
        if self.report_data["constant_analysis"]:
            for const, data in self.report_data["constant_analysis"].items():
                if "correlation_analysis" in data:
                    correlation = data["correlation_analysis"].get("correlation_score", 0)
                    if correlation > 0.5:
                        findings.append(f"ğŸ”— {const.upper()} ä¸DNAåºåˆ—å­˜åœ¨è¾ƒå¼ºå…³è”ï¼ˆå…³è”å¾—åˆ†: {correlation:.2f}ï¼‰")
        
        if findings:
            for finding in findings:
                report_lines.append(f"- {finding}")
        else:
            report_lines.append("âš ï¸ æœªå‘ç°æ˜¾è‘—çš„å…³é”®ç»“æœ")
        
        report_lines.append("")
        
        # å»ºè®®å’Œæ”¹è¿›æ–¹å‘
        report_lines.append("## 8. å»ºè®®å’Œæ”¹è¿›æ–¹å‘")
        report_lines.append("")
        
        suggestions = [
            "1. **å¢å¼ºé²æ£’æ€§æµ‹è¯•**: æ·»åŠ æ›´å¤šè¾¹ç¼˜æƒ…å†µæµ‹è¯•ï¼Œå¦‚æé•¿åºåˆ—ã€ç‰¹æ®Šå­—ç¬¦è¾“å…¥ç­‰",
            "2. **ä¼˜åŒ–é›¶å‡è®¾éªŒè¯**: å¢åŠ éšæœºåºåˆ—æ•°é‡ï¼Œæé«˜ç»Ÿè®¡æ£€éªŒçš„å¯é æ€§",
            "3. **æ‰©å±•å¸¸æ•°åˆ†æ**: åˆ†ææ›´å¤šæ•°å­¦å¸¸æ•°å’Œç‰©ç†å¸¸æ•°ï¼Œå¯»æ‰¾æ›´å¹¿æ³›çš„å…³è”",
            "4. **æ”¹è¿›æ€§èƒ½**: ä¼˜åŒ–å¤§åºåˆ—å¤„ç†é€Ÿåº¦ï¼Œå‡å°‘å†…å­˜ä½¿ç”¨",
            "5. **å¢åŠ å¯è§†åŒ–**: æ·»åŠ ç»“æœå¯è§†åŒ–åŠŸèƒ½ï¼Œä½¿åˆ†æç»“æœæ›´ç›´è§‚",
            "6. **æ‰©å±•åº”ç”¨åœºæ™¯**: æ¢ç´¢åœ¨æ›´å¤šç”Ÿç‰©ä¿¡æ¯å­¦é¢†åŸŸçš„åº”ç”¨",
            "7. **å®Œå–„æ–‡æ¡£**: å¢åŠ è¯¦ç»†çš„ä½¿ç”¨æ–‡æ¡£å’ŒAPIå‚è€ƒ",
            "8. **æŒç»­é›†æˆ**: å»ºç«‹è‡ªåŠ¨åŒ–æµ‹è¯•å’Œéƒ¨ç½²æµç¨‹"
        ]
        
        for suggestion in suggestions:
            report_lines.append(suggestion)
        
        report_lines.append("")
        
        # ç»“è®º
        report_lines.append("## 9. ç»“è®º")
        report_lines.append("")
        
        if "performance" in self.report_data:
            overall_score = self.report_data["performance"].get("overall_score", 0)
            
            if overall_score >= 80:
                conclusion = "DNAåˆ†æç³»ç»Ÿè¡¨ç°ä¼˜ç§€ï¼Œåœ¨é²æ£’æ€§ã€ç»Ÿè®¡æ˜¾è‘—æ€§å’Œæ•°å­¦å¸¸æ•°å…³è”æ–¹é¢éƒ½å–å¾—äº†è‰¯å¥½çš„ç»“æœã€‚ç³»ç»Ÿè®¾è®¡åˆç†ï¼Œå®ç°äº†å¶æ•°é•¿åº¦åºåˆ—å¤„ç†ã€é›¶å‡è®¾éªŒè¯å’Œé²æ£’æ€§æµ‹è¯•ç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚å»ºè®®ç»§ç»­ä¼˜åŒ–å’Œæ‰©å±•ç³»ç»Ÿèƒ½åŠ›ï¼Œæ¢ç´¢æ›´å¤šåº”ç”¨åœºæ™¯ã€‚"
            elif overall_score >= 60:
                conclusion = "DNAåˆ†æç³»ç»Ÿè¡¨ç°åŸºæœ¬åˆæ ¼ï¼Œå®ç°äº†æ ¸å¿ƒåŠŸèƒ½å¹¶é€šè¿‡äº†å¤§éƒ¨åˆ†æµ‹è¯•ã€‚ä½†åœ¨æŸäº›æ–¹é¢ä»æœ‰æ”¹è¿›ç©ºé—´ï¼Œå¦‚é²æ£’æ€§æµ‹è¯•è¦†ç›–ç‡å’Œç»Ÿè®¡æ˜¾è‘—æ€§æ°´å¹³ã€‚å»ºè®®é’ˆå¯¹å‘ç°çš„é—®é¢˜è¿›è¡Œæœ‰é’ˆå¯¹æ€§çš„æ”¹è¿›ã€‚"
            else:
                conclusion = "DNAåˆ†æç³»ç»Ÿéœ€è¦æ˜¾è‘—æ”¹è¿›ï¼Œåœ¨å¤šä¸ªæ–¹é¢è¡¨ç°ä¸ä½³ã€‚å»ºè®®é‡æ–°è¯„ä¼°ç³»ç»Ÿè®¾è®¡ï¼ŒåŠ å¼ºæµ‹è¯•è¦†ç›–ï¼Œæé«˜ç»Ÿè®¡åˆ†æçš„å¯é æ€§ï¼Œå¹¶ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ã€‚"
        else:
            conclusion = "ç”±äºç¼ºä¹è¶³å¤Ÿçš„æµ‹è¯•æ•°æ®ï¼Œæ— æ³•å¯¹ç³»ç»Ÿæ€§èƒ½åšå‡ºå…¨é¢è¯„ä¼°ã€‚å»ºè®®é¦–å…ˆå®Œå–„æµ‹è¯•æµç¨‹ï¼Œæ”¶é›†æ›´å¤šåˆ†æç»“æœï¼Œç„¶åå†è¿›è¡Œç³»ç»Ÿè¯„ä¼°ã€‚"
        
        report_lines.append(conclusion)
        report_lines.append("")
        
        # é™„å½•
        report_lines.append("## 10. é™„å½•")
        report_lines.append("")
        report_lines.append("### 10.1 åˆ†ææ–‡ä»¶æ¸…å•")
        report_lines.append("")
        
        # åˆ—å‡ºæ‰€æœ‰åˆ†ææ–‡ä»¶
        analysis_files = []
        for root, dirs, files in os.walk(self.base_dir):
            for file in files:
                if file.endswith('.json') and any(keyword in file for keyword in ['result', 'robustness', 'analysis']):
                    file_path = os.path.join(root, file)
                    relative_path = os.path.relpath(file_path, self.base_dir)
                    file_size = os.path.getsize(file_path) / 1024  # KB
                    analysis_files.append(f"- `{relative_path}` ({file_size:.1f} KB)")
        
        for file_info in analysis_files:
            report_lines.append(file_info)
        
        return "\n".join(report_lines)
    
    def save_report(self, output_file):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Š"""
        # åŠ è½½æ‰€æœ‰åˆ†æç»“æœ
        self.load_robustness_test_results()
        self.load_standard_analysis_results()
        self.load_null_hypothesis_test_results()
        self.load_batch_analysis_results()
        self.load_constant_analysis_results()
        
        # è®¡ç®—æ•´ä½“æ€§èƒ½
        self.calculate_overall_performance()
        
        # ç”ŸæˆæŠ¥å‘Š
        report_content = self.generate_markdown_report()
        
        # ä¿å­˜æŠ¥å‘Š
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_file}")
        return output_file

if __name__ == "__main__":
    # å½“å‰ç›®å½•
    base_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š
    generator = SystemEvaluationReportGenerator(base_dir)
    output_file = os.path.join(base_dir, "dna_analysis_system_evaluation_report.md")
    generator.save_report(output_file)
    
    print("\næŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print(f"è¯·æŸ¥çœ‹æ–‡ä»¶: {output_file}")
